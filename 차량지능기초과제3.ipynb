{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "차량지능기초과제3",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kthfighting/20161298project1/blob/master/%EC%B0%A8%EB%9F%89%EC%A7%80%EB%8A%A5%EA%B8%B0%EC%B4%88%EA%B3%BC%EC%A0%9C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuQ5UpVHx0Ds"
      },
      "source": [
        "!git clone https://github.com/Lhyejin/LaneNet-PyTorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUXqT-oFx8eV"
      },
      "source": [
        "%cd LaneNet-PyTorch//\n",
        "!ls\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfeVm2pbHTAI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5B85XEOx9vN"
      },
      "source": [
        "import os.path as ops\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from dataset.dataset_utils import TUSIMPLE\n",
        "from Lanenet.model2 import Lanenet\n",
        "from utils.evaluation import gray_to_rgb_emb, process_instance_embedding\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Load the Model\n",
        "model_path = './TUSIMPLE/Lanenet_output/lanenet_epoch_39_batch_8.model'\n",
        "LaneNet_model = Lanenet(2, 4)\n",
        "LaneNet_model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
        "LaneNet_model.to(device)\n",
        "\n",
        "def inference(gt_img_org):\n",
        "    # BGR 순서\n",
        "    org_shape = gt_img_org.shape\n",
        "    gt_image = cv2.resize(gt_img_org, dsize=(512, 256), interpolation=cv2.INTER_LINEAR)\n",
        "    gt_image = gt_image / 127.5 - 1.0\n",
        "    gt_image = torch.tensor(gt_image, dtype=torch.float)\n",
        "    gt_image = np.transpose(gt_image, (2, 0, 1))\n",
        "    gt_image = gt_image.to(device)\n",
        "    # lane segmentation \n",
        "    binary_final_logits, instance_embedding = LaneNet_model(gt_image.unsqueeze(0))\n",
        "    binary_final_logits, instance_embedding = binary_final_logits.to('cpu'), instance_embedding.to('cpu') \n",
        "    binary_img = torch.argmax(binary_final_logits, dim=1).squeeze().numpy()\n",
        "    binary_img[0:65,:] = 0\n",
        "\n",
        "    # lane clustering & segemented frame embedding\n",
        "    rbg_emb, cluster_result = process_instance_embedding(instance_embedding, binary_img,\n",
        "                                                          distance=1.5, lane_num=4)\n",
        "\n",
        "    rbg_emb = cv2.resize(rbg_emb, dsize=(org_shape[1], org_shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "    a = 0.6\n",
        "    frame = a * gt_img_org[..., ::-1] / 255 + rbg_emb * (1 - a)\n",
        "    frame = np.rint(frame * 255)\n",
        "    frame = frame.astype(np.uint8)\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "image = cv2.imread('TUSIMPLE/test_clips/1494452927854312215/1.jpg')\n",
        "cv2_imshow(inference(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aosKlj1AzHj3"
      },
      "source": [
        "import os.path as ops\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from dataset.dataset_utils import TUSIMPLE\n",
        "from Lanenet.model2 import Lanenet\n",
        "from utils.evaluation import gray_to_rgb_emb, process_instance_embedding\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def video2segemented_video(video_path):\n",
        "    # TODO: video to frames\n",
        "   cap = cv2.VideoCapture(video_path)\n",
        "   count=0\n",
        "  \n",
        "   \n",
        "   while (count<12):\n",
        "    ret, frame = cap.read()\n",
        "    try:\n",
        "      frame =cv2.resize(frame, (960, 540))\n",
        "    except cv2.error:\n",
        "      continue\n",
        "\n",
        "    if(int(cap.get(1))% 30 ==0):\n",
        "      print('Saved frame number : '+str(int(cap.get(1))))\n",
        "      cv2.imwrite(\"/content/drive/MyDrive/frames/frame%d.jpg\" % count, frame) \n",
        "      if cv2.waitKey(42)==ord('q'):\n",
        "        break   \n",
        "      count+=1  \n",
        "      print(\"count+1\") \n",
        "   cap.release()\n",
        "   cv2.destroyAllWindows()\n",
        "    # TODO: extract lane from frame\n",
        "\n",
        "   count=0\n",
        "\n",
        "   while(count<12):\n",
        "     image = cv2.imread('/content/drive/MyDrive/frames/frame%d.jpg' % count)\n",
        "     image=inference(image)\n",
        "     try:\n",
        "      cv2.imwrite(\"/content/drive/MyDrive/nframes/frame%d.jpg\" % count, image)\n",
        "     except cv2.error:\n",
        "      continue\n",
        "     print(\"%d downloaded\" % count)\n",
        "     count+=1\n",
        "\n",
        "\n",
        "    # TODO: frames to video & store video\n",
        "   import re\n",
        "   path = \"/content/drive/MyDrive/nframes\"\n",
        "   paths = [os.path.join(path , i ) for i in os.listdir(path) if re.search(\".jpg$\", i )]\n",
        "\n",
        "   store1 = []\n",
        "   store2 = []\n",
        "   for i in paths :\n",
        "      if len(i) == 19 :\n",
        "          store2.append(i)\n",
        "      else :\n",
        "          store1.append(i)\n",
        "\n",
        "   paths = list(np.sort(store1)) + list(np.sort(store2))\n",
        "\n",
        "   pathIn= '/content/drive/MyDrive/'\n",
        "   pathOut = '/content/drive/MyDrive/out.mp4'\n",
        "   fps = 1\n",
        "   frame_array = []\n",
        "   for idx , path in enumerate(paths) : \n",
        "    if (idx % 2 == 0) | (idx % 5 == 0) :\n",
        "        continue\n",
        "    img = cv2.imread(path)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    frame_array.append(img)\n",
        "   out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "   for i in range(len(frame_array)):    \n",
        "    out.write(frame_array[i])\n",
        "   out.release()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNakHYTK0RdH"
      },
      "source": [
        "# Test\n",
        "video_path = \"/content/drive/MyDrive/video_example_Trim.mp4\" # input your video path\n",
        "video2segemented_video(video_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}